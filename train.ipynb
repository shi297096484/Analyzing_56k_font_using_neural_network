{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5105)\n",
      "/home/ubuntu/miniconda2/envs/theano/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy\n",
    "import theano\n",
    "import model\n",
    "import sys\n",
    "import functools\n",
    "import time\n",
    "from scipy.ndimage import filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(dataset, batch_size=512):\n",
    "    random.shuffle(dataset)\n",
    "    for offset in xrange(0, len(dataset), batch_size):\n",
    "        s = min(batch_size, len(dataset) - offset)\n",
    "        batch_fonts = numpy.zeros((s,), dtype=numpy.int32)\n",
    "        batch_chars = numpy.zeros((s,), dtype=numpy.int32)\n",
    "        batch_ds = numpy.zeros((s, wh), dtype=theano.config.floatX)\n",
    "        for z in xrange(s):\n",
    "            i, j = dataset[offset + z]\n",
    "            batch_fonts[z] = i\n",
    "            batch_chars[z] = j\n",
    "            m = filters.gaussian_filter(data[i][j], sigma=random.random()*1.0) # data augmentation\n",
    "            batch_ds[z] = m.flatten() * 1. / 255\n",
    "\n",
    "        yield s, 1.0 * offset / len(dataset), batch_fonts, batch_chars, batch_ds\n",
    "\n",
    "        \n",
    "def iterate_run(dataset, fn, tag):\n",
    "    total_loss, total_reg, total_count = 0, 0, 0\n",
    "    for s, progress, input_font, input_char, output in iterate_minibatches(dataset):\n",
    "        t0 = time.time()\n",
    "        loss, reg = fn(input_font, input_char, output)\n",
    "        t = time.time() - t0\n",
    "        total_loss += float(loss) * s\n",
    "        total_reg += float(reg) * s\n",
    "        total_count += s\n",
    "        sys.stdout.write('%s: %6.2f%%, perf: %.6f + %.6f (last minibatch: %.6f + %.6f, %.3fs)\\r' % (tag, 100.0 * progress, total_loss / total_count, total_reg / total_count, float(loss), float(reg), t))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    sys.stdout.write('\\n')\n",
    "    return total_loss / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = model.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n, k = data.shape[0], data.shape[1]\n",
    "wh = data.shape[2] * data.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "loading model...\n"
     ]
    }
   ],
   "source": [
    "model = model.Model(n, k, wh)\n",
    "model.try_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling training fn\n"
     ]
    }
   ],
   "source": [
    "train_fn_w_learning_rate = model.get_train_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling testing fn\n"
     ]
    }
   ],
   "source": [
    "test_fn = model.get_test_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_fn = model.get_run_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = model.sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "epoch 0 learning rate 0.1\n",
      "\n",
      "\n",
      "loss 0.074229\n",
      "saving model...\n",
      "epoch 1 learning rate 0.1\n",
      "\n",
      "\n",
      "loss 0.074231\n",
      "saving model...\n",
      "epoch 2 learning rate 0.1\n",
      "\n",
      "\n",
      "loss 0.074104\n",
      "saving model...\n",
      "epoch 3 learning rate 0.1\n",
      "\n",
      "\n",
      "loss 0.074128\n",
      "saving model...\n",
      "epoch 4 learning rate 0.1\n",
      "\n",
      "\n",
      "loss 0.074118\n",
      "saving model...\n",
      "epoch 5 learning rate 0.1\n",
      "\n",
      "\n",
      "loss 0.074054\n",
      "saving model...\n",
      "epoch 6 learning rate 0.1\n",
      "\n",
      "\n",
      "loss 0.074011\n",
      "saving model...\n",
      "epoch 7 learning rate 0.1\n",
      "\n",
      "\n",
      "loss 0.074002\n",
      "saving model...\n",
      "epoch 8 learning rate 0.1\n",
      "\n",
      "\n",
      "loss 0.073985\n",
      "saving model...\n",
      "epoch 9 learning rate 0.1\n",
      "\n",
      "\n",
      "loss 0.074002\n",
      "epoch 0 learning rate 0.03\n",
      "\n",
      "\n",
      "loss 0.073958\n",
      "saving model...\n",
      "epoch 1 learning rate 0.03\n",
      "\n",
      "\n",
      "loss 0.073945\n",
      "saving model...\n",
      "epoch 2 learning rate 0.03\n",
      "\n",
      "\n",
      "loss 0.073978\n",
      "saving model...\n",
      "epoch 3 learning rate 0.03\n",
      "\n",
      "\n",
      "loss 0.073959\n",
      "saving model...\n",
      "epoch 4 learning rate 0.03\n",
      "\n",
      "\n",
      "loss 0.073926\n",
      "saving model...\n",
      "epoch 5 learning rate 0.03\n",
      "\n",
      "\n",
      "loss 0.073921\n",
      "saving model...\n",
      "epoch 6 learning rate 0.03\n",
      "\n",
      "\n",
      "loss 0.073907\n",
      "saving model...\n",
      "epoch 7 learning rate 0.03\n",
      "\n",
      "\n",
      "loss 0.073877\n",
      "saving model...\n",
      "epoch 8 learning rate 0.03\n",
      "\n",
      "\n",
      "loss 0.073915\n",
      "epoch 0 learning rate 0.01\n",
      "\n",
      "\n",
      "loss 0.073905\n",
      "saving model...\n",
      "epoch 1 learning rate 0.01\n",
      "\n",
      "\n",
      "loss 0.073904\n",
      "saving model...\n",
      "epoch 2 learning rate 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a36a906c41b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'learning rate'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtrain_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_fn_w_learning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0miterate_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miterate_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loss %f\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-cf07ecc7935a>\u001b[0m in \u001b[0;36miterate_run\u001b[1;34m(dataset, fn, tag)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0miterate_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_font\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_font\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-cf07ecc7935a>\u001b[0m in \u001b[0;36miterate_minibatches\u001b[1;34m(dataset, batch_size)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mbatch_chars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgaussian_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# data augmentation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mbatch_ds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0moffset\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_fonts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_chars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print 'training...'\n",
    "for learning_rate in [1.0, 0.3, 0.1, 0.03, 0.01]:\n",
    "    epoch, last_loss = 0, float('inf')\n",
    "    while True:\n",
    "        print 'epoch', epoch, 'learning rate', learning_rate\n",
    "        train_fn = functools.partial(train_fn_w_learning_rate, learning_rate)\n",
    "        iterate_run(train_set, train_fn, 'train')\n",
    "        loss = iterate_run(test_set, test_fn, 'test ')\n",
    "        print(\"loss %f\" %loss)\n",
    "        if loss > last_loss and epoch > 3:\n",
    "            break # decrease learning rate\n",
    "        last_loss = loss\n",
    "        model.save()\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "epoch 0 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.074849\n",
      "saving model...\n",
      "epoch 1 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.073718\n",
      "saving model...\n",
      "epoch 2 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.072789\n",
      "saving model...\n",
      "epoch 3 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.071707\n",
      "saving model...\n",
      "epoch 4 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.071026\n",
      "saving model...\n",
      "epoch 5 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.070240\n",
      "saving model...\n",
      "epoch 6 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.069701\n",
      "saving model...\n",
      "epoch 7 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.069079\n",
      "saving model...\n",
      "epoch 8 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.068495\n",
      "saving model...\n",
      "epoch 9 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.068081\n",
      "saving model...\n",
      "epoch 10 learning rate 1.0\n",
      "\n",
      "loss 0.067449\n",
      "saving model...\n",
      "epoch 11 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.066961\n",
      "saving model...\n",
      "epoch 12 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.066516\n",
      "saving model...\n",
      "epoch 13 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.066041\n",
      "saving model...\n",
      "epoch 14 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.065604\n",
      "saving model...\n",
      "epoch 15 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.065316\n",
      "saving model...\n",
      "epoch 16 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.064997\n",
      "saving model...\n",
      "epoch 17 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.064611\n",
      "saving model...\n",
      "epoch 18 learning rate 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ff05e0b5afd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'learning rate'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtrain_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_fn_w_learning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0miterate_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miterate_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loss %f\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-cf07ecc7935a>\u001b[0m in \u001b[0;36miterate_run\u001b[1;34m(dataset, fn, tag)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_font\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_font\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/envs/theano/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    864\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print 'training...'\n",
    "for learning_rate in [1.0, 0.3, 0.1, 0.03, 0.01]:\n",
    "    epoch, last_loss = 0, float('inf')\n",
    "    while True:\n",
    "        print 'epoch', epoch, 'learning rate', learning_rate\n",
    "        train_fn = functools.partial(train_fn_w_learning_rate, learning_rate)\n",
    "        iterate_run(train_set, train_fn, 'train')\n",
    "        loss = iterate_run(test_set, test_fn, 'test ')\n",
    "        print(\"loss %f\" %loss)\n",
    "        if loss > last_loss and epoch > 3:\n",
    "            break # decrease learning rate\n",
    "        last_loss = loss\n",
    "        model.save()\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "epoch 0 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.064243\n",
      "saving model...\n",
      "epoch 1 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.063967\n",
      "saving model...\n",
      "epoch 2 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.063709\n",
      "saving model...\n",
      "epoch 3 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.063458\n",
      "saving model...\n",
      "epoch 4 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.063176\n",
      "saving model...\n",
      "epoch 5 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.062975\n",
      "saving model...\n",
      "epoch 6 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.062768\n",
      "saving model...\n",
      "epoch 7 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.062544\n",
      "saving model...\n",
      "epoch 8 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.062310\n",
      "saving model...\n",
      "epoch 9 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.062109\n",
      "saving model...\n",
      "epoch 10 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.061922\n",
      "saving model...\n",
      "epoch 11 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.061718\n",
      "saving model...\n",
      "epoch 12 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.061554\n",
      "saving model...\n",
      "epoch 13 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.061429\n",
      "saving model...\n",
      "epoch 14 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.061263\n",
      "saving model...\n",
      "epoch 15 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.061043\n",
      "saving model...\n",
      "epoch 16 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.060912\n",
      "saving model...\n",
      "epoch 17 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.060773\n",
      "saving model...\n",
      "epoch 18 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.060567\n",
      "saving model...\n",
      "epoch 19 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.060501\n",
      "saving model...\n",
      "epoch 20 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.060333\n",
      "saving model...\n",
      "epoch 21 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.060236\n",
      "saving model...\n",
      "epoch 22 learning rate 1.0\n",
      "\n",
      "\n",
      "loss 0.060085\n",
      "saving model...\n",
      "epoch 23 learning rate 1.0\n"
     ]
    }
   ],
   "source": [
    "print 'training...'\n",
    "for learning_rate in [1.0, 0.3, 0.1, 0.03, 0.01]:\n",
    "    epoch, last_loss = 0, float('inf')\n",
    "    while True:\n",
    "        print 'epoch', epoch, 'learning rate', learning_rate\n",
    "        train_fn = functools.partial(train_fn_w_learning_rate, learning_rate)\n",
    "        iterate_run(train_set, train_fn, 'train')\n",
    "        loss = iterate_run(test_set, test_fn, 'test ')\n",
    "        print(\"loss %f\" %loss)\n",
    "        if loss > last_loss and epoch > 3:\n",
    "            break # decrease learning rate\n",
    "        last_loss = loss\n",
    "        model.save()\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
